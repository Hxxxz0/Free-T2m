# Free-T2M: Frequency-Enhanced Text-to-Motion Diffusion Model ğŸš€

Free-T2M is a cutting-edge diffusion-based framework designed for **text-to-motion generation**. By leveraging **frequency-domain analysis** and **stage-specific consistency losses**, Free-T2M significantly enhances the robustness and precision of motion generation. The model introduces innovative **low-frequency consistency guidance** and **semantic consistency mechanisms**, achieving **state-of-the-art (SOTA)** performance across various benchmarks. ğŸŒŸ

## Key Features ğŸ› ï¸

- **Frequency-Domain Analysis**: Incorporates low-frequency components to improve semantic alignment during the denoising process, ensuring smoother and more natural motion generation. ğŸ“Š
- **Consistency Losses**: Combines **low-frequency consistency** and **semantic consistency** losses to ensure stable and accurate motion generation, reducing artifacts and enhancing realism. âš–ï¸
- **State-of-the-Art Performance**: Demonstrates significant improvements in motion quality, achieving **SOTA results** on the **HumanML3D** and **KIT-ML** benchmarks. ğŸ†

## Why Free-T2M? ğŸ¤”

Free-T2M stands out by integrating advanced frequency-domain techniques with robust consistency mechanisms, making it a powerful tool for generating high-quality, semantically aligned motions from text descriptions. Whether for animation, robotics, or virtual reality, Free-T2M sets a new standard in text-to-motion generation. ğŸ¯

## Performance Highlights ğŸ“ˆ

- **FID Reduction**: Achieves a significant reduction in FID on the MDM baseline, improving from **0.544** to **0.256**.
- **SOTA on StableMoFusion**: Reduces FID from **0.189** to **0.051**, establishing a new benchmark within the diffusion architecture.
- **Human Subjective Evaluations**: Demonstrates substantial improvements in human subjective evaluations, further validating its superiority.

## Getting Started ğŸš€

To get started with Free-T2M, clone the repository and follow the setup instructions in the `README.md` file. We welcome contributions and feedback to further enhance the capabilities of Free-T2M.


Feel free to explore the repository and contribute to the future of motion generation! ğŸš€âœ¨
